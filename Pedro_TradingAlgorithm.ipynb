{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90226339-2635-4900-8b2d-4493ddfa8b32",
   "metadata": {},
   "source": [
    "# Pedro - Short Queeze Predictor\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e14a3b-aea3-4fe7-8f9c-a064d2f5cb0c",
   "metadata": {},
   "source": [
    "### 1. Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9b99c-97af-487e-9ec8-e3f9dabc4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffc9dd-9527-4215-8790-b8721ef281d0",
   "metadata": {},
   "source": [
    "### 2. Alpaca API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092e9bf-9595-425e-9f9b-5f80e5139295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alpaca_api():\n",
    "    load_dotenv(dotenv_path=\"Alpaca.env\")\n",
    "\n",
    "    alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "    alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "    alpaca_api_base_url = \"https://paper-api.alpaca.markets\"\n",
    "\n",
    "    api = tradeapi.REST(\n",
    "        alpaca_api_key,\n",
    "        alpaca_secret_key,\n",
    "        alpaca_api_base_url,\n",
    "        api_version=\"v2\"\n",
    "    )\n",
    "\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d278736-a4a1-466b-9f41-fd2ec1d8ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = create_alpaca_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f835f-6c45-46d0-a637-ac0528ba2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get account information\n",
    "account = api.get_account()\n",
    "\n",
    "# Check if our account is restricted from trading.\n",
    "if account.trading_blocked:\n",
    "    print('Account is currently restricted from trading.')\n",
    "\n",
    "# Print our current balance.\n",
    "print('${} is available as buying power.'.format(account.buying_power))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6004cc-4da7-45d2-967e-7fda4e17d80a",
   "metadata": {},
   "source": [
    "### 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d0386-5906-4df1-a487-86a84d8e8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_names, folder_path='Models'):\n",
    "    \"\"\"\n",
    "    Loads trained models based on the given model names from the specified folder.\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    for name in model_names:\n",
    "        # Load each model from its file in the 'Models' folder\n",
    "        if name == \"Neural_Network\":\n",
    "            models[name] = load_model(os.path.join(folder_path, f\"{name.replace(' ', '_')}.h5\"))\n",
    "        else:\n",
    "            models[name] = joblib.load(os.path.join(folder_path, f\"{name.replace(' ', '_')}.joblib\"))\n",
    "        \n",
    "    return models\n",
    "\n",
    "print(\"Function 'load_models' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b0a64-15a9-4708-a18c-486f01645d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_names = [\"Gradient_Boosting_Classifier\", \"Support_Vector_Classifier\", \n",
    "               \"Random_Forest_Classifier\", \"Decision_Tree_Classifier\", \n",
    "               \"XGBoost_Classifier\", \"Neural_Network\"]\n",
    "\n",
    "models = load_models(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169fe26-f2b8-46e1-8a6c-29c2c4b99791",
   "metadata": {},
   "source": [
    "### 4. Load New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046aff84-5bf9-4f7f-8cbc-ea58e0b1b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\n",
    "    Path(\"Resources/NewData.csv\"), #We dont have the NewData (Live Data)\n",
    "    parse_dates=True,\n",
    "    infer_datetime_format=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49249c0-4811-43d7-98bb-c495d8c01929",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272ea67-5ed9-4afb-929e-6fc37c21a611",
   "metadata": {},
   "source": [
    "### 5. Preprocess the New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af411974-0024-452a-ba37-f965d89be67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the StandardScaler and OneHotEncoder\n",
    "scaler = joblib.load('Models/scaler.joblib') \n",
    "encoder = joblib.load('Models/encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f729b7-d5b6-4bea-a153-0666c931f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = ['Short % of Float', 'Market Cap', '% from 50 day MA']  # replace with your actual numerical features\n",
    "categorical_features = ['Sector'] # replace with your actual categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead403a-4fea-49bf-9663-680d3afd397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply StandardScaler to the numerical columns of new_data\n",
    "new_data[numerical_features] = scaler.transform(new_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ade26-47bf-440c-b7cd-8e3f4840aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply OneHotEncoder to the categorical columns of new_data\n",
    "encoded_data = encoder.transform(new_data[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_features), index=new_data.index)\n",
    "numerical_df = new_data.drop(columns=categorical_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00ae2f-7dfe-412e-8d21-e81124f16f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the numerical and encoded categorical data\n",
    "encoded_new_data = pd.concat([numerical_df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413a26a-3aec-4316-a037-54af584eee04",
   "metadata": {},
   "source": [
    "### 6. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151de6e-9264-45bd-a10c-56aa4ce29cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    predictions[name] = model.predict(encoded_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29574f91-89f7-49d6-b1e4-a75e03d5bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out predictions\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions from {name}: {preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad20bfa-3977-455a-8332-0d11fc9d6d41",
   "metadata": {},
   "source": [
    "### 7. Buy/Sell Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150ae0c-d71c-4dff-95ee-652285368048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_order(api, symbol, notional, side='buy', type='market', time_in_force='gtc'):\n",
    "    api.submit_order(\n",
    "        symbol=symbol,\n",
    "        qty=notional,  # Alpaca uses \"qty\" instead of \"notional\" for specifying the quantity\n",
    "        side=side,\n",
    "        type=type,\n",
    "        time_in_force=time_in_force\n",
    "    )\n",
    "\n",
    "print(\"Function 'place_order' defined.\")\n",
    "\n",
    "# Define the stock symbol and the notional amount to buy\n",
    "symbol = \"AAPL\"  # replace with your actual symbol\n",
    "notional = 1000  # replace with your actual notional amount in USD\n",
    "\n",
    "# Assuming you have a way to determine the quantity of shares to buy based on 'new_data'\n",
    "new_data = get_new_data()  # Replace with your function to retrieve new data\n",
    "\n",
    "# Determine the quantity of shares to buy based on 'new_data'\n",
    "quantity = calculate_quantity(new_data)  # Replace with your own logic to calculate the quantity\n",
    "\n",
    "# Call the buy function\n",
    "place_order(api, symbol, quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5b9c0-ac3b-498f-9bd4-3180ad97dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sell_signal(api, symbol, notional, data):\n",
    "    sell = False\n",
    "\n",
    "    # Checking if Return (5 Days) or Return (7 Days) >= 10%\n",
    "    if (data['Return (5 Days)'] >= 10).any() or (data['Return (7 Days)'] >= 10).any():\n",
    "        sell = True\n",
    "    # Checking if Return (15 Days) >= 15%\n",
    "    elif (data['Return (15 Days)'] >= 15).any():\n",
    "        sell = True\n",
    "    # Checking if Return (30 Days) >= 20%\n",
    "    elif (data['Return (30 Days)'] >= 20).any():\n",
    "        sell = True\n",
    "\n",
    "    if sell:\n",
    "        print(\"Sell Signal: Short Squeeze detected.\")\n",
    "        sell_order(api, symbol, notional)\n",
    "    else:\n",
    "        print(\"No Sell Signal: Short Squeeze not detected.\")\n",
    "\n",
    "def sell_order(api, symbol, notional, side='sell', type='market', time_in_force='gtc'):\n",
    "    api.submit_order(\n",
    "        symbol=symbol,\n",
    "        qty=notional,\n",
    "        side=side,\n",
    "        type=type,\n",
    "        time_in_force=time_in_force\n",
    "    )\n",
    "\n",
    "print(\"Functions defined.\")\n",
    "\n",
    "# Define the stock symbol and the notional amount to sell\n",
    "symbol = \"AAPL\"  \n",
    "notional = 1000 \n",
    "\n",
    "# Assuming you have a way to determine the quantity of shares to buy based on 'new_data'\n",
    "new_data = get_new_data()  # Replace with your function to retrieve new data\n",
    "\n",
    "# Call the buy/sell signal function with the new data\n",
    "sell_signal(api, symbol, notional, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6964b2-1a57-488c-8bc1-3b889b199536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
