{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d747d1a4-8886-4542-9a9b-7a688ce24204",
   "metadata": {},
   "source": [
    "# Pedro - Short Queeze Predictor\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b61898-777a-4387-a889-cdf838a3f7ed",
   "metadata": {},
   "source": [
    "### 1. Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fc2c9-97c4-4fd6-8bd8-2900aa31ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import pandas_market_calendars as mcal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f87b9a-5895-41ac-8484-d83d60b3c992",
   "metadata": {},
   "source": [
    "### 2. Data Preparation Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c0e3a-b298-447d-8f98-e5da85bcb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Desired_Days = [1, 2, 5, 7, 15, 30]\n",
    "ShortFloat = 17\n",
    "MarketCap = 300000000\n",
    "Insider_Amount = 500000\n",
    "short_float_filepath = \"Resources/ShortFloat.csv\"\n",
    "insider_trading_filepath = \"Resources/InsiderTrading.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498dce6-bef6-4cc3-b2a8-b26438528f8d",
   "metadata": {},
   "source": [
    "### 3. Data Loading and Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8f33b-19df-4275-be14-0fdd94dc6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(short_float_filepath, insider_trading_filepath):\n",
    "    \n",
    "    short_df = pd.read_csv(short_float_filepath)\n",
    "    short_df.rename(columns={'ShortSqueeze.com Short Interest Data': 'Company Name'}, inplace=True)\n",
    "    # Dropping irrelevant columns\n",
    "    columns_to_drop = [\n",
    "    'Total Short Interest', 'Days to Cover', 'Performance (52-wk)', 'Short: Prior Mo', '% Change Mo/Mo',\n",
    "    'Shares: Float', 'Avg. Daily Vol.', 'Shares: Outstanding', 'Short Squeeze Rankingâ„¢', '% from 52-wk High',\n",
    "    '(abs)', '% from 200 day MA', '(abs).1', '% from 50 day MA', '(abs).2',\n",
    "    '% Institutional Ownership'\n",
    "    ]\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in short_df.columns]\n",
    "    short_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    # Convert 'Short % of Float' and 'Market Cap' to numeric and apply filters\n",
    "    short_df['Short % of Float'] = pd.to_numeric(short_df['Short % of Float'], errors='coerce')\n",
    "    short_df = short_df[short_df['Short % of Float'] >= ShortFloat]\n",
    "    short_df['Market Cap'] = pd.to_numeric(short_df['Market Cap'], errors='coerce')\n",
    "    short_df = short_df[short_df['Market Cap'] >= MarketCap]\n",
    "    \n",
    "    insider_df = pd.read_csv(insider_trading_filepath)\n",
    "    insider_df['Total Amount'] = insider_df['Total Amount'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "    insider_df['Share Price'] = insider_df['Share Price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "    insider_df['Date'] = pd.to_datetime(insider_df['Date'])\n",
    "    insider_df['Total Amount'] = pd.to_numeric(insider_df['Total Amount'], errors='coerce')\n",
    "    insider_df = insider_df[insider_df['Total Amount'] >= Insider_Amount]\n",
    "    \n",
    "    return short_df, insider_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec1ac5-7185-4437-b4e9-47b3ff42d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "short_df, insider_df = load_and_preprocess_data(short_float_filepath, insider_trading_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375af6ff-e752-4ab8-9c5e-c9d0af0bbcb2",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f546b-0487-4b88-9511-059fa6c58620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(short_df, insider_df):\n",
    "    date_mapping = {\n",
    "    'JanA': '01-11', 'JanB': '01-25',\n",
    "    'FebA': '02-09', 'FebB': '02-27',\n",
    "    'MarA': '03-09', 'MarB': '03-24',\n",
    "    'AprA': '04-12', 'AprB': '04-25',\n",
    "    'MayA': '05-09', 'MayB': '05-24',\n",
    "    'JunA': '06-09', 'JunB': '06-27',\n",
    "    'JulA': '07-12', 'JulB': '07-25',\n",
    "    'AugA': '08-09', 'AugB': '08-24',\n",
    "    'SepA': '09-12', 'SepB': '09-26',\n",
    "    'OctA': '10-10', 'OctB': '10-24',\n",
    "    'NovA': '11-09', 'NovB': '11-27',\n",
    "    'DecA': '12-11', 'DecB': '12-27',\n",
    "    }\n",
    "    \n",
    "    short_df['Record Date'] = pd.to_datetime(short_df['Record Date'].str.replace(r'(\\d{4})-(\\w+)', lambda m: f'{m.group(1)}-{date_mapping[m.group(2)]}'))\n",
    "    short_df.sort_values('Record Date', inplace=True)\n",
    "    short_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_df = pd.merge(short_df, insider_df, on='Symbol')\n",
    "    merged_df['Share Price'] = merged_df['Share Price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "    merged_df = merged_df[['Symbol', 'Short % of Float', 'Total Amount', '% Insider Ownership', 'Record Date', 'Share Price', 'Company Name', 'Sector', 'Industry', 'Date']]\n",
    "    \n",
    "    # Calculate the difference between 'Date' and 'Record Date' for each row\n",
    "    merged_df['Date_diff'] = (merged_df['Date'] - merged_df['Record Date']).dt.days\n",
    "    # Filter out rows where 'Date_diff' is more than 30 and drop unnecessary columns\n",
    "    merged_df = merged_df[merged_df['Date_diff'] >= 0]\n",
    "    merged_df.sort_values(['Symbol', 'Date_diff'], inplace=True)\n",
    "    merged_df.drop_duplicates(subset=['Symbol', 'Date'], keep='first', inplace=True)\n",
    "    merged_df = merged_df[merged_df['Date_diff'] <= 30]\n",
    "    merged_df.drop(columns=['Record Date', 'Date_diff'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    new_column_order = ['Symbol', 'Short % of Float', 'Total Amount', '% Insider Ownership', 'Date', 'Company Name', 'Sector', 'Industry']\n",
    "    merged_df = merged_df[new_column_order]\n",
    "    \n",
    "    # Create new columns for Close Prices at future dates and calculate Returns.\n",
    "    nyse = mcal.get_calendar('NYSE')\n",
    "    \n",
    "    for day in Desired_Days:\n",
    "        merged_df[f'Close Price Day {day}'] = np.nan\n",
    "\n",
    "    for idx, row in merged_df.iterrows():\n",
    "        trading_days = nyse.valid_days(start_date=row['Date'], end_date=row['Date'] + pd.DateOffset(days=45))\n",
    "\n",
    "        for day in Desired_Days:\n",
    "            if day <= len(trading_days):\n",
    "                data = yf.download(row['Symbol'], start=trading_days[day - 1], end=trading_days[day - 1] + pd.DateOffset(days=1))\n",
    "                if not data.empty:  \n",
    "                    merged_df.loc[idx, f'Close Price Day {day}'] = data['Close'][0] \n",
    "    \n",
    "    # Calculate Returns and Highest Day Return\n",
    "    for day in Desired_Days: \n",
    "        merged_df[f'Return ({day} Days)'] = ((merged_df[f'Close Price Day {day}'] - merged_df['Close Price Day 1']) / merged_df['Close Price Day 1']) * 100\n",
    "        \n",
    "    merged_df['Highest Day Return'] = merged_df[[f'Return ({day} Days)' for day in Desired_Days]].max(axis=1)\n",
    "    merged_df['Highest Close Price'] = merged_df[[f'Close Price Day {day}' for day in Desired_Days]].max(axis=1)\n",
    "    \n",
    "    for col in merged_df.columns:\n",
    "        if 'Close Price' in col or 'Return' in col:\n",
    "            merged_df[col] = merged_df[col].round(2)\n",
    "\n",
    "    merged_df.dropna(inplace=True)\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_df['Short Squeeze'] = 0\n",
    "    # Checking if Return (5 Days) and/or Return (7 Days) >= 10\n",
    "    mask = ((merged_df['Return (5 Days)'] >= 10) | (merged_df['Return (7 Days)'] >= 10))\n",
    "    merged_df.loc[mask, 'Short Squeeze'] = 1\n",
    "    # Checking if Return (15 Days) >= 15\n",
    "    mask = (merged_df['Return (15 Days)'] >= 15)\n",
    "    merged_df.loc[mask, 'Short Squeeze'] = 1\n",
    "    # Checking if Return (30 Days) >= 25\n",
    "    mask = (merged_df['Return (30 Days)'] >= 25)\n",
    "    merged_df.loc[mask, 'Short Squeeze'] = 1\n",
    "    # Setting other cases to 0\n",
    "    merged_df.loc[merged_df['Short Squeeze'] != 1, 'Short Squeeze'] = 0\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518804e0-ef6f-41d9-a7d9-b1951cd362d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "merged_df = feature_engineering(short_df, insider_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be00f4-1f09-4d3b-8cf8-da3dd7db1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short Squeeze vs. Non Short Squeeze Counts in DataFrame\n",
    "short_squeeze_count = merged_df.loc[merged_df['Short Squeeze'] == 1, 'Short Squeeze'].count()\n",
    "no_short_squeeze_count = merged_df.loc[merged_df['Short Squeeze'] == 0, 'Short Squeeze'].count()\n",
    "\n",
    "print(\"Short Squeeze\", short_squeeze_count)\n",
    "print(\"Non Short Squeeze\", no_short_squeeze_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2748674-d886-478e-ac62-014db1d67bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f43cc8-9319-4961-aa3f-488176efcc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('Resources/ShortSqueezeData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b35f9b-c678-4371-83de-929131f3fdff",
   "metadata": {},
   "source": [
    "### 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eaf40f-a582-4c0c-bd53-8c6639de6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Short Squeeze\n",
    "short_squeeze_df = merged_df[merged_df['Short Squeeze'] == 1]\n",
    "grouped_df = short_squeeze_df.groupby('Symbol')\n",
    "for symbol, data in grouped_df:\n",
    "    data = data.sort_values('Date')\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    days_to_plot = Desired_Days\n",
    "    closing_prices = [data[f'Close Price Day {day}'].iloc[-1] for day in days_to_plot]\n",
    "    plt.plot(days_to_plot, closing_prices, 'o', color='blue')\n",
    "    highest_closing_price = max(closing_prices)\n",
    "    highest_closing_price_day = days_to_plot[closing_prices.index(highest_closing_price)]\n",
    "    plt.plot(highest_closing_price_day, highest_closing_price, 'ro')\n",
    "    plt.annotate('Highest Closing Price',\n",
    "                 xy=(highest_closing_price_day, highest_closing_price),\n",
    "                 xytext=(highest_closing_price_day + 0.5, highest_closing_price),\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "                 fontsize=8,\n",
    "                 ha='left')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.title(f'Short Squeeze: {symbol}')\n",
    "    plt.xticks(days_to_plot, [f'Day {day}' for day in days_to_plot])\n",
    "    plt.grid(True)\n",
    "    filename = f\"Images/{symbol}_close_short_squeeze_plot.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092770ab-503e-4e74-b5f6-2f88c67fb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at each short squeeze company 30 days before and after Insider Trading activity occurs\n",
    "for symbol, data in grouped_df:\n",
    "    start_date = pd.to_datetime(data['Date'].min()) - pd.DateOffset(days=30)\n",
    "    end_date = pd.to_datetime(data['Date'].max()) + pd.DateOffset(days=30)\n",
    "    yf_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "    close_prices = yf_data['Close']\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.plot(close_prices.index, close_prices.values)\n",
    "    plt.title(f'{symbol} Short Squeeze')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.xticks(rotation=45)  # Rotate the x-axis labels by 45 degrees\n",
    "    plt.grid(True)\n",
    "    filename = f\"Images/{symbol}_short_squeeze_plot.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ee5d7-336c-4eac-883a-cfb9264e395e",
   "metadata": {},
   "source": [
    "### 6. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffbefb-b2d0-4945-ac33-8ed06d5430e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    categorical_variables = ['Company Name', 'Sector', 'Industry']\n",
    "    encoded_df = pd.DataFrame(encoder.fit_transform(df[categorical_variables]))\n",
    "    encoded_df.columns = encoder.get_feature_names_out(categorical_variables)\n",
    "    numerical_df = df.drop(columns=categorical_variables, axis=1)\n",
    "    return pd.concat([numerical_df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244d34b-2520-403e-abf8-b922146f798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the data\n",
    "merged_df = one_hot_encode(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fd204-a236-40aa-aa5d-f14120485e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30bdda-3b7e-4442-87c2-2a25df929b38",
   "metadata": {},
   "source": [
    "### 7. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f3482b-a1de-49ec-832d-3d26a3ff83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.drop(columns=['Short Squeeze'])\n",
    "y = merged_df['Short Squeeze']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97530b-412e-42b3-b7d9-70cec7721374",
   "metadata": {},
   "source": [
    "### 8. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b3632-5e3e-4876-9797-c4094b7a5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Symbol' column from X_train and X_test\n",
    "X_train_scaled = X_train.drop('Symbol', axis=1)\n",
    "X_test_scaled = X_test.drop('Symbol', axis=1)\n",
    "\n",
    "# Drop the 'Date' column from X_train and X_test\n",
    "X_train_scaled = X_train_scaled.drop('Date', axis=1)\n",
    "X_test_scaled = X_test_scaled.drop('Date', axis=1)\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "X_test_scaled = scaler.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6387c-dc72-4bc8-bb05-8c2ccfc0fb2e",
   "metadata": {},
   "source": [
    "### 9. Model Training (FNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4ce2e-a325-4859-840e-2f9c9b7b96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a13c3-08a8-408d-9764-e2c23f18d561",
   "metadata": {},
   "source": [
    "### 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db89a54-a2c4-4253-a824-a4e528c63d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1af90-05dc-4bf4-a472-c14f85163ee5",
   "metadata": {},
   "source": [
    "### 11. Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae278fc-d0f4-46d7-899a-a6a72e5c26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "# Since this is a binary classification problem, we'll set a threshold at 0.5\n",
    "predictions = [1 if pred > 0.5 else 0 for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607a9d9-ae20-4013-af8e-58d633da15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might want to compare these predictions with the actual values\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "\n",
    "# Print out a sample of the comparison DataFrame\n",
    "print(comparison_df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6007e-635d-4b28-ada9-1907d38a6b1e",
   "metadata": {},
   "source": [
    "### 12. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4c8d8-342a-4520-a46b-e73807680f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b298c-4b7c-4819-a1d4-b3dddebfb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('fnn_model')\n",
    "\n",
    "# Load the model later\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('fnn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d1570-b481-48a0-a200-af4668e9a101",
   "metadata": {},
   "source": [
    "## Alternative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72529cc6-106f-4981-83e0-0b35d3fcab80",
   "metadata": {},
   "source": [
    "### Random Forest vs SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2c856-d6bc-41af-80a5-245e8756c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the distinct values in the original labels data\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca517cc-540a-465e-94dd-36835971ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "rf_predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08669c35-d286-4767-ab8f-70ffdf90fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a sample of the comparison DataFrame\n",
    "rf_comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': rf_predictions})\n",
    "print(\"Random Forest Results Sample\")\n",
    "print(rf_comparison_df.sample(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab946a-5d0f-4580-8209-fb5eec3760aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance metrics\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "print(confusion_matrix(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f7eb3-a0ab-4a4c-9491-7ea1f9a5ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "dump(rf_model, 'rf_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6437b0a-88f8-47d4-9ed4-0bd5ddb45c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model later\n",
    "loaded_rf_model = load('rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3652501-e5dd-4941-9261-db5705790eb6",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a18f23-849c-4008-b27e-8758ccd993b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SMOTE\n",
    "smote_sampler = SMOTE(random_state=1, sampling_strategy='minority')\n",
    "\n",
    "# Fit the SMOTE model to the data\n",
    "X_resampled, y_resampled = smote_sampler.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e10467-18ab-4838-a791-3be0c8953f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the distinct values in the resampled labels data\n",
    "print(f\"SMOTE distribution: {y_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31f06f-d755-4b83-b8ad-02e40295bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "smote_model = RandomForestClassifier(n_estimators=100, random_state=1).fit(X_resampled, y_resampled)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "smote_predictions = smote_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807f97e-9a3f-4fea-90c9-dfec67473a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a sample of the comparison DataFrame\n",
    "smote_comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': smote_predictions})\n",
    "print(\"SMOTE Results Sample\")\n",
    "print(smote_comparison_df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3cfab-d8c9-43ee-9a72-76e06c16e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance metrics\n",
    "print(classification_report(y_test, smote_predictions))\n",
    "print(confusion_matrix(y_test, smote_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdc4b1-6d43-4bf2-b044-42f9ec4ecebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "dump(smote_model, 'smote_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f96df4-ea64-4662-a530-d3aa94932972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model later\n",
    "loaded_smote_model = load('smote_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ec0ad-fd70-4028-b52a-193323c3b1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
