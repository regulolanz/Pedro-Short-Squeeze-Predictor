{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d747d1a4-8886-4542-9a9b-7a688ce24204",
   "metadata": {},
   "source": [
    "# Pedro - Short Queeze Predictor\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25650702-99fc-488f-b9dc-320ac574371e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc6fc2c9-97c4-4fd6-8bd8-2900aa31ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the project\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "import pandas_market_calendars as mcal\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f87b9a-5895-41ac-8484-d83d60b3c992",
   "metadata": {},
   "source": [
    "### Short Interest Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45d8f33b-19df-4275-be14-0fdd94dc6ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/regulolanz/anaconda3/envs/dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess short interest data\n",
    "short_df = pd.read_csv(Path(\"Resources/ShortFloat.csv\"))\n",
    "short_df.rename(columns={'ShortSqueeze.com Short Interest Data': 'Company Name'}, inplace=True)\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "columns_to_drop = [\n",
    "    'Total Short Interest', 'Days to Cover', 'Performance (52-wk)', 'Short: Prior Mo', '% Change Mo/Mo',\n",
    "    'Shares: Float', 'Avg. Daily Vol.', 'Shares: Outstanding', 'Short Squeeze Rankingâ„¢', '% from 52-wk High',\n",
    "    '(abs)', '% from 200 day MA', '(abs).1', '% from 50 day MA', '(abs).2', '% Insider Ownership',\n",
    "    '% Institutional Ownership'\n",
    "]\n",
    "columns_to_drop = [col for col in columns_to_drop if col in short_df.columns]\n",
    "short_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Convert 'Short % of Float' and 'Market Cap' to numeric and apply filters\n",
    "short_df['Short % of Float'] = pd.to_numeric(short_df['Short % of Float'], errors='coerce')\n",
    "short_df = short_df[short_df['Short % of Float'] >= 17]\n",
    "short_df['Market Cap'] = pd.to_numeric(short_df['Market Cap'], errors='coerce')\n",
    "short_df = short_df[short_df['Market Cap'] >= 300000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120417d4-e74f-48bf-803d-57fb651bb5e0",
   "metadata": {},
   "source": [
    "### Date Cleaning and Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a14f546b-0487-4b88-9511-059fa6c58620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/regulolanz/anaconda3/envs/dev/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'Record Date' column to datetime, sort the dataframe by 'Record Date'.\n",
    "date_mapping = {\n",
    "    'JanA': '01-11', 'JanB': '01-25',\n",
    "    'FebA': '02-09', 'FebB': '02-27',\n",
    "    'MarA': '03-09', 'MarB': '03-24',\n",
    "    'AprA': '04-12', 'AprB': '04-25',\n",
    "    'MayA': '05-09', 'MayB': '05-24',\n",
    "    'JunA': '06-09', 'JunB': '06-27',\n",
    "    'JulA': '07-12', 'JulB': '07-25',\n",
    "    'AugA': '08-09', 'AugB': '08-24',\n",
    "    'SepA': '09-12', 'SepB': '09-26',\n",
    "    'OctA': '10-10', 'OctB': '10-24',\n",
    "    'NovA': '11-09', 'NovB': '11-27',\n",
    "    'DecA': '12-11', 'DecB': '12-27',\n",
    "}\n",
    "short_df['Record Date'] = pd.to_datetime(short_df['Record Date'].str.replace(r'(\\d{4})-(\\w+)', lambda m: f'{m.group(1)}-{date_mapping[m.group(2)]}'))\n",
    "short_df.sort_values('Record Date', inplace=True)\n",
    "short_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a8602-f1fe-44c5-b593-acb5241ad935",
   "metadata": {},
   "source": [
    "### Insider Trading Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a79556b-9b55-4ec0-8c9c-705d16a9f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load insider trading data, remove dollar symbols, and convert columns to numeric\n",
    "insider_df = pd.read_csv(\"Resources/InsiderTrading.csv\")\n",
    "insider_df['Total Amount'] = insider_df['Total Amount'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "insider_df['Share Price'] = insider_df['Share Price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "insider_df['Date'] = pd.to_datetime(insider_df['Date'])\n",
    "insider_df['Total Amount'] = pd.to_numeric(insider_df['Total Amount'], errors='coerce')\n",
    "insider_df = insider_df[insider_df['Total Amount'] >= 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6cb797-bf50-4ff9-8e2a-405178203cf9",
   "metadata": {},
   "source": [
    "### Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "628db501-f3fb-4b60-b9b3-fa8c2406c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge short_df and insider_df based on the Symbol column, rename columns, and select necessary columns\n",
    "merged_df = pd.merge(short_df, insider_df, on='Symbol')\n",
    "merged_df['Share Price'] = merged_df['Share Price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "merged_df = merged_df[['Symbol', 'Short % of Float', 'Total Amount', 'Record Date', 'Share Price', 'Company Name', 'Sector', 'Industry', 'Date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9503889-1b9e-4b54-a1a9-37c0a1534fb2",
   "metadata": {},
   "source": [
    "### Data Cleaning and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e255c0e1-9461-4465-a4fe-b442bae0dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between 'Date' and 'Record Date' for each row\n",
    "merged_df['Date_diff'] = (merged_df['Date'] - merged_df['Record Date']).dt.days\n",
    "\n",
    "# Filter out rows where 'Date_diff' is more than 30 and drop unnecessary columns\n",
    "merged_df = merged_df[merged_df['Date_diff'] >= 0]\n",
    "merged_df.sort_values(['Symbol', 'Date_diff'], inplace=True)\n",
    "merged_df.drop_duplicates(subset=['Symbol', 'Date'], keep='first', inplace=True)\n",
    "merged_df = merged_df[merged_df['Date_diff'] <= 30]\n",
    "merged_df.drop(columns=['Record Date', 'Date_diff'], inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "new_column_order = ['Symbol', 'Short % of Float', 'Total Amount', 'Date', 'Company Name', 'Sector', 'Industry']\n",
    "merged_df = merged_df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0215c50c-a59f-42c1-b9c1-efc2f35e8e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Short % of Float</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Date</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AKRO</td>\n",
       "      <td>26.46</td>\n",
       "      <td>10400000.00</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>Akero Therapeutics Inc</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Biotechnology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>ASAN</td>\n",
       "      <td>26.61</td>\n",
       "      <td>3498910.93</td>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>Asana Inc. Class A Common Stock</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Software - Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>ASAN</td>\n",
       "      <td>26.61</td>\n",
       "      <td>1400743.32</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>Asana Inc. Class A Common Stock</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Software - Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>ASAN</td>\n",
       "      <td>26.61</td>\n",
       "      <td>1035540.04</td>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>Asana Inc. Class A Common Stock</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Software - Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>ASAN</td>\n",
       "      <td>26.61</td>\n",
       "      <td>12355033.74</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>Asana Inc. Class A Common Stock</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Software - Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>TCDA</td>\n",
       "      <td>19.15</td>\n",
       "      <td>1717048.89</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>Tricida Inc</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>TCDA</td>\n",
       "      <td>19.15</td>\n",
       "      <td>5397432.60</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>Tricida Inc</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>UWMC</td>\n",
       "      <td>24.79</td>\n",
       "      <td>1010056.36</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>UWM Holdings Corporation Class A Common Stock</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mortgage Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>W</td>\n",
       "      <td>21.38</td>\n",
       "      <td>1222400.00</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>Wayfair Inc Class A</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Internet Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>W</td>\n",
       "      <td>29.20</td>\n",
       "      <td>1745100.00</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>Wayfair Inc Class A</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Internet Retail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol  Short % of Float  Total Amount       Date  \\\n",
       "32     AKRO             26.46   10400000.00 2022-09-19   \n",
       "650    ASAN             26.61    3498910.93 2022-02-09   \n",
       "641    ASAN             26.61    1400743.32 2022-02-10   \n",
       "637    ASAN             26.61    1035540.04 2022-02-11   \n",
       "632    ASAN             26.61   12355033.74 2022-02-16   \n",
       "...     ...               ...           ...        ...   \n",
       "5173   TCDA             19.15    1717048.89 2022-09-06   \n",
       "5172   TCDA             19.15    5397432.60 2022-09-07   \n",
       "4401   UWMC             24.79    1010056.36 2022-05-12   \n",
       "415       W             21.38    1222400.00 2022-03-03   \n",
       "424       W             29.20    1745100.00 2022-05-19   \n",
       "\n",
       "                                       Company Name              Sector  \\\n",
       "32                           Akero Therapeutics Inc          Healthcare   \n",
       "650                 Asana Inc. Class A Common Stock          Technology   \n",
       "641                 Asana Inc. Class A Common Stock          Technology   \n",
       "637                 Asana Inc. Class A Common Stock          Technology   \n",
       "632                 Asana Inc. Class A Common Stock          Technology   \n",
       "...                                             ...                 ...   \n",
       "5173                                    Tricida Inc          Healthcare   \n",
       "5172                                    Tricida Inc          Healthcare   \n",
       "4401  UWM Holdings Corporation Class A Common Stock  Financial Services   \n",
       "415                             Wayfair Inc Class A   Consumer Cyclical   \n",
       "424                             Wayfair Inc Class A   Consumer Cyclical   \n",
       "\n",
       "                                      Industry  \n",
       "32                               Biotechnology  \n",
       "650                     Software - Application  \n",
       "641                     Software - Application  \n",
       "637                     Software - Application  \n",
       "632                     Software - Application  \n",
       "...                                        ...  \n",
       "5173  Drug Manufacturers - Specialty & Generic  \n",
       "5172  Drug Manufacturers - Specialty & Generic  \n",
       "4401                          Mortgage Finance  \n",
       "415                            Internet Retail  \n",
       "424                            Internet Retail  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624acc4a-ec8d-4f75-8603-d35b4795a22e",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b0961-99a7-41cc-99f8-e3531729d1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Create new columns for Close Prices at future dates and calculate Returns.\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "desired_days = [1, 2, 3, 4, 5, 7]\n",
    "for day in desired_days:\n",
    "    merged_df[f'Close Price Day {day}'] = np.nan\n",
    "\n",
    "for idx, row in merged_df.iterrows():\n",
    "    trading_days = nyse.valid_days(start_date=row['Date'], end_date=row['Date'] + pd.DateOffset(days=10))\n",
    "\n",
    "    for day in desired_days:\n",
    "        if day <= len(trading_days):\n",
    "            data = yf.download(row['Symbol'], start=trading_days[day - 1], end=trading_days[day - 1] + pd.DateOffset(days=1))\n",
    "            if not data.empty:  \n",
    "                merged_df.loc[idx, f'Close Price Day {day}'] = data['Close'][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c773f-3f1c-4f58-b062-552482a7b485",
   "metadata": {},
   "source": [
    "### Calculate Returns and Highest Day Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca0c28-2ca6-4052-87cb-83672571855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in [5, 7]: \n",
    "    merged_df[f'Return ({day} Days)'] = ((merged_df[f'Close Price Day {day}'] - merged_df['Close Price Day 1']) / merged_df['Close Price Day 1']) * 100\n",
    "\n",
    "merged_df['Highest Day Return'] = merged_df[[f'Return ({day} Days)' for day in [5, 7]]].max(axis=1)\n",
    "merged_df['Highest Close Price'] = merged_df[[f'Close Price Day {day}' for day in desired_days]].max(axis=1)\n",
    "\n",
    "# Format the 'Close Price' and 'Return' columns to have 2 decimal places\n",
    "for col in merged_df.columns:\n",
    "    if 'Close Price' in col or 'Return' in col:\n",
    "        merged_df[col] = merged_df[col].round(2)\n",
    "\n",
    "# Drop NaNs and reset the index\n",
    "merged_df.dropna(inplace=True)\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8ee54-df77-4d2a-aa25-3d3833852534",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd506853-9ef6-413a-bfc0-86d330d50228",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Short Squeeze'] = 0\n",
    "merged_df.loc[merged_df['Highest Day Return'] >= 20, 'Short Squeeze'] = 1\n",
    "merged_df.loc[merged_df['Highest Day Return'] < 20, 'Short Squeeze'] = 0\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d29aa-783d-437a-9b12-90848f3f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the dataframe for further analysis\n",
    "transposed_df = merged_df.T\n",
    "transposed_df = transposed_df.drop(['Company Name', 'Date', 'Sector', 'Industry'])\n",
    "transposed_df.set_axis(transposed_df.loc['Symbol'], axis=1, inplace=True)\n",
    "transposed_df.drop('Symbol', inplace=True)\n",
    "\n",
    "# Display the transposed dataframe\n",
    "transposed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791860b4-b949-4392-9b43-5806cd4e248e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f3cb6-9529-4ab6-b08d-c9bab745552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the data types associated with the columns\n",
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f8b9e-abe2-411a-9613-0c5b11555994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = list(merged_df.select_dtypes(\"object\").columns)\n",
    "\n",
    "# Display the categorical variables list\n",
    "display(categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da2e54-b52c-4fd3-ab0c-10b0771ece25",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f677db-e207-4073-b084-6940f5832e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(merged_df[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a063e6e-dc8d-44ed-9d44-00d8d4e51991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(encoded_data, columns = enc.get_feature_names(categorical_variables))\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d931a-85ff-494e-8abd-cfd6e926df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "encoded_df = pd.concat([merged_df.select_dtypes([\"int64\", \"float64\"]), encoded_df], axis=1)\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede137ea-5fac-45e8-97bd-b8f198604106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the features from the target\n",
    "X = encoded_df.drop(columns='Short Squeeze')\n",
    "y = encoded_df['Short Squeeze']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c73619-c997-45ec-8d78-ce1d56e90d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ad650-0125-4454-9dd4-760e4f0a82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
